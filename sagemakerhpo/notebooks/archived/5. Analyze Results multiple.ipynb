{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.<br /><br />Licensed under the Amazon Software License (the \"License\"). You may not<br />use this file except in compliance with the License. A copy of the<br />License is located at:<br />   http://aws.amazon.com/asl/<br />or in the \"license\" file accompanying this file. This file is distributed<br />on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express<br />or implied. See the License for the specific language governing permissions<br />and limitations under the License.\n",
    "# Analyze tuning job results in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smhpolib.analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_REGION\"] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the names of lots of tuning jobs here...\n",
    "TUNING_JOB_NAMES=[\n",
    "    \"tuning-job-1\",\n",
    "    \"tuning-job-2\",\n",
    "    \"tuning-job-3\",#...\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load all the tuning jobs for analysis\n",
    "import pandas as pd\n",
    "df_list = []\n",
    "for tuning_job_name in TUNING_JOB_NAMES:\n",
    "    tuning = smhpolib.analysis.TuningJob(tuning_job_name, max_training_jobs=500)\n",
    "    df_this = tuning.hyperparam_dataframe()\n",
    "    df_this['TuningJobName'] = tuning_job_name\n",
    "    df_list.append(df_this)\n",
    "    df = pd.concat(df_list)\n",
    "    print(\"Fetched %s: %d more total %d\" % (tuning_job_name, len(df_this), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('TuningJobName').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on those with a value FinalObjectiveValue\n",
    "all_df=df\n",
    "print(\"Total: %d\" % len(all_df))\n",
    "df = all_df[df['FinalObjectiveValue'] > -float('inf')]\n",
    "print(\"Valid objective: %d\" % len(df))\n",
    "# and sort it so the best show up at top\n",
    "df = df.sort_values('FinalObjectiveValue', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)  # Don't truncate TrainingJobName\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See TuningJob results vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "import bokeh.palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_warp_palette(size, palette_func, warp=1):\n",
    "    \"\"\"setting warp < 1 exagerates the high end.\n",
    "    setting warp > 1 exagerates the low end\"\"\"\n",
    "    p = palette_func(256)\n",
    "    out = []\n",
    "    for i in range(size):\n",
    "        f = i / (size - 1.0) # from 0-1 inclusive\n",
    "        f **= warp\n",
    "        idx = int(f * 255)\n",
    "        out.append(p[idx])\n",
    "    return out\n",
    "\n",
    "palette = big_warp_palette(len(df),bokeh.palettes.plasma, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=900, plot_height=400)\n",
    "p.circle(df['TrainingStartTime'],df['FinalObjectiveValue'],color=palette)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df['FinalObjectiveValue']), max(df['FinalObjectiveValue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Look at correlation between objective and individual HP's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which hyperparameters to look for correlations for\n",
    "all_hyperparameters = tuning.hyperparam_ranges().keys()\n",
    "all_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('FinalObjectiveValue', ascending=False)\n",
    "for hp in all_hyperparameters:\n",
    "    p = figure(plot_width=500, plot_height=500, \n",
    "                title=\"Final objective vs %s\" % hp,\n",
    "                x_axis_label=hp, y_axis_label=\"objective\")\n",
    "    p.circle(df[hp],df['FinalObjectiveValue'], color=palette)\n",
    "    show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Correlations between hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the full browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def warp_size(cnt,lo,hi,warp):\n",
    "    out = list(hi - np.arange(0,1,1.0/cnt)**warp * (hi-lo))\n",
    "    out = out[:cnt]  # Sometimes arange has a rounding error and gives +1\n",
    "    return out\n",
    "sizes = warp_size(len(df),2,10,0.5)\n",
    "# Plot the better points larger.  Good to have a lower warp here, so that the medium-good points are still large, but only the really good ones are large and purple\n",
    "opacity = warp_size(len(df),0.5,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import bokeh.layouts\n",
    "screen_width_px = 1200\n",
    "plot_sz = int(screen_width_px / len(all_hyperparameters))\n",
    "figures = []\n",
    "for j, hp2 in enumerate(all_hyperparameters):\n",
    "    figure_row = []\n",
    "    for i, hp1 in enumerate(all_hyperparameters):\n",
    "        #if i>=j: continue  # only show lower diagonal\n",
    "        #if i>j: continue  # only lower diagonal, include self-corr\n",
    "        p = figure(plot_width=plot_sz, plot_height=plot_sz, \n",
    "               x_axis_label=hp1, y_axis_label=hp2)\n",
    "        p.toolbar_location = None\n",
    "        p.toolbar.logo = None\n",
    "        p.circle(list(df[hp1]),list(df[hp2]), alpha=0.7, size=sizes, color=palette)\n",
    "        figure_row.append(p)\n",
    "    figures.append(figure_row)\n",
    "show(bokeh.layouts.gridplot(children=figures))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
