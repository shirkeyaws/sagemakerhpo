{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.<br /><br />Licensed under the Amazon Software License (the \"License\"). You may not<br />use this file except in compliance with the License. A copy of the<br />License is located at:<br />   http://aws.amazon.com/asl/<br />or in the \"license\" file accompanying this file. This file is distributed<br />on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express<br />or implied. See the License for the specific language governing permissions<br />and limitations under the License.\n",
    "# Analyze tuning job results in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smhpolib.analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region='us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_REGION\"] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_JOB_NAME='your-tuning-job-name'\n",
    "tuning = smhpolib.analysis.TuningJob(TUNING_JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tuning.training_job_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally add in some other metrics that were recorded\n",
    "#tuning.add_metric('train-score', \"final\")\n",
    "#tuning.add_metric('valid-score', \"final\")\n",
    "print(tuning.metric_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_df = tuning.hyperparam_dataframe()\n",
    "# Filter on those with a value FinalObjectiveValue\n",
    "print(\"Total: %d\" % len(all_df))\n",
    "df = all_df[all_df['FinalObjectiveValue'] > -float('inf')]\n",
    "print(\"Valid objective: %d\" % len(df))\n",
    "# and sort it so the best show up at top\n",
    "df = df.sort_values('FinalObjectiveValue', ascending=False)\n",
    "print({\"lowest\":min(df['FinalObjectiveValue']),\"highest\": max(df['FinalObjectiveValue'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)  # Don't truncate TrainingJobName\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See TuningJob results vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "import bokeh.palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_warp_palette(size, palette_func, warp=1):\n",
    "    \"\"\"setting warp < 1 exagerates the high end.\n",
    "    setting warp > 1 exagerates the low end\"\"\"\n",
    "    p = palette_func(256)\n",
    "    out = []\n",
    "    for i in range(size):\n",
    "        f = i / (size - 1.0) # from 0-1 inclusive\n",
    "        f **= warp\n",
    "        idx = int(f * 255)\n",
    "        out.append(p[idx])\n",
    "    return out\n",
    "\n",
    "palette = big_warp_palette(len(df),bokeh.palettes.plasma, 0.4)\n",
    "df['color'] = palette\n",
    "hover = smhpolib.viz.SmhpoHover(tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=900, plot_height=400, tools=hover.tools(), x_axis_type='datetime')\n",
    "p.circle(source=df, x='TrainingStartTime', y='FinalObjectiveValue', color='color')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Look at correlation between objective and individual HP's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which hyperparameters to look for correlations for\n",
    "all_hyperparameters = tuning.hyperparam_ranges().keys()\n",
    "all_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figures = []\n",
    "for hp in all_hyperparameters:\n",
    "    p = figure(plot_width=500, plot_height=500, \n",
    "                title=\"Final objective vs %s\" % hp,\n",
    "                tools=hover.tools(),\n",
    "                x_axis_label=hp, y_axis_label=\"objective\")\n",
    "    p.circle(source=df,x=hp,y='FinalObjectiveValue',color='color')\n",
    "    figures.append(p)\n",
    "show(bokeh.layouts.Column(*figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Correlations between hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the full browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def warp_size(cnt,lo,hi,warp):\n",
    "    return hi - np.arange(0,1,1.0/cnt)**warp * (hi-lo)\n",
    "sizes = warp_size(len(df),2,15,0.7)\n",
    "df['sizes']=sizes\n",
    "# Plot the better points larger.  Good to have a lower warp here, \n",
    "# so that the medium-good points are still large, but only the really good ones are large and purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import bokeh.layouts\n",
    "screen_width_px = 1200\n",
    "plot_sz = int(screen_width_px / len(all_hyperparameters))\n",
    "figures = []\n",
    "for j, hp2 in enumerate(all_hyperparameters):\n",
    "    figure_row = []\n",
    "    for i, hp1 in enumerate(all_hyperparameters):\n",
    "        #if i>=j: continue  # only show lower diagonal\n",
    "        #if i>j: continue  # only lower diagonal, include self-corr\n",
    "        p = figure(plot_width=plot_sz, plot_height=plot_sz, \n",
    "                tools=hover.tools(),\n",
    "                x_axis_label=hp1, y_axis_label=hp2)\n",
    "        p.toolbar_location = None\n",
    "        p.toolbar.logo = None\n",
    "        p.circle(source=df, x=hp1, y=hp2, alpha=0.7, size='sizes', color='color')\n",
    "        figure_row.append(p)\n",
    "    figures.append(figure_row)\n",
    "show(bokeh.layouts.gridplot(children=figures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
