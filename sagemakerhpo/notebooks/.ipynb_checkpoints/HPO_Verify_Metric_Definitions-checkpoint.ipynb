{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.<br /><br />Licensed under the Amazon Software License (the \"License\"). You may not<br />use this file except in compliance with the License. A copy of the<br />License is located at:<br />   http://aws.amazon.com/asl/<br />or in the \"license\" file accompanying this file. This file is distributed<br />on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express<br />or implied. See the License for the specific language governing permissions<br />and limitations under the License.\n",
    "# Verifying metric definitions\n",
    "\n",
    "This notebook helps you verify that your metric definitions are behaving the way you expect them to.\n",
    "It lets you quickly try different regular expressions (regexes) on actual TrainingJob log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up training jobs & metrics from a tuning job\n",
    "To test metric definitions, we'll apply them to CloudWatch logs from real training jobs.\n",
    "The easiest way to get both of these is from an actual HyperParamaterTuningJob, which we'll show here.\n",
    "You can override these if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_JOB_NAME='xgboost-tuningjob-21-14-31-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 training jobs starting with ['xgboost-tuningjob-21-14-31-09-020-5b3b2be0', 'xgboost-tuningjob-21-14-31-09-019-ffb835b5', 'xgboost-tuningjob-21-14-31-09-018-ad3f88ee', 'xgboost-tuningjob-21-14-31-09-017-40c72940', 'xgboost-tuningjob-21-14-31-09-016-1b5dac84']\n"
     ]
    }
   ],
   "source": [
    "training_job_list = sagemaker.list_training_jobs_for_hyper_parameter_tuning_job(HyperParameterTuningJobName=TUNING_JOB_NAME)['TrainingJobSummaries']\n",
    "training_job_names = [desc['TrainingJobName'] for desc in training_job_list]\n",
    "print(\"Found %d training jobs starting with %s\" % (len(training_job_names), training_job_names[:5]))\n",
    "# Note: this will be an incomplete list for large tuning jobs, because we're not paginating through the results.\n",
    "# This is fine for what we're doing, which is just verifying -- we just need a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using logs for training job xgboost-tuningjob-21-14-31-09-020-5b3b2be0\n"
     ]
    }
   ],
   "source": [
    "# Pick the specific training job to try applying metrics to.  You can specify it explicitly here if you want.\n",
    "# TRAINING_JOB_NAME = 'your-training-job-name'  \n",
    "# But by default, we'll take the first one from the tuning job.\n",
    "TRAINING_JOB_NAME = training_job_names[0]\n",
    "print(\"Using logs for training job %s\" % TRAINING_JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found metric definitions:\n",
      "[{'Name': 'train:mae', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-mae:(\\\\S+).*'},\n",
      " {'Name': 'validation:auc',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-auc:(\\\\S+)'},\n",
      " {'Name': 'train:merror', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-merror:(\\\\S+).*'},\n",
      " {'Name': 'train:auc', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-auc:(\\\\S+).*'},\n",
      " {'Name': 'validation:mae',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mae:(\\\\S+)'},\n",
      " {'Name': 'validation:error',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-error:(\\\\S+)'},\n",
      " {'Name': 'validation:merror',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-merror:(\\\\S+)'},\n",
      " {'Name': 'validation:logloss',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-logloss:(\\\\S+)'},\n",
      " {'Name': 'train:rmse', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-merror:(\\\\S+).*'},\n",
      " {'Name': 'train:logloss', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-logloss:(\\\\S+).*'},\n",
      " {'Name': 'train:mlogloss',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\]#011train-mlogloss:(\\\\S+).*'},\n",
      " {'Name': 'validation:rmse',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-rmse:(\\\\S+)'},\n",
      " {'Name': 'validation:ndcg',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-ndcg:(\\\\S+)'},\n",
      " {'Name': 'train:error', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-error:(\\\\S+).*'},\n",
      " {'Name': 'validation:mlogloss',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-logloss:(\\\\S+)'},\n",
      " {'Name': 'train:ndcg', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-ndcg:(\\\\S+).*'},\n",
      " {'Name': 'train:map', 'Regex': '.*\\\\[[0-9]+\\\\]#011train-map:(\\\\S+).*'},\n",
      " {'Name': 'validation:map',\n",
      "  'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-map:(\\\\S+)'}]\n"
     ]
    }
   ],
   "source": [
    "# Now get the metric definitions\n",
    "tuning_job_desc = sagemaker.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=TUNING_JOB_NAME)\n",
    "metric_definitions = tuning_job_desc['TrainingJobDefinition']['AlgorithmSpecification']['MetricDefinitions']\n",
    "print(\"Found metric definitions:\")\n",
    "from pprint import pprint\n",
    "pprint(metric_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch TrainingJob log from CloudWatch and apply MetricDefinition to it\n",
    "Simulate the exist metric definitions in that hyperparamter tuning job on the first training job's log.\n",
    "Then later we'll try changing the regex and see how that works on the same log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "cwl = boto3.client(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find log streams for this training job\n",
    "log_stream_descs = cwl.describe_log_streams(logGroupName=\"/aws/sagemaker/TrainingJobs\", \n",
    "                                            logStreamNamePrefix=TRAINING_JOB_NAME)['logStreams']\n",
    "# Just pick the first one\n",
    "log_stream = log_stream_descs[0]['logStreamName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "class MetricDefinitionVerifier(object):\n",
    "    \n",
    "    def __init__(self, metric_definitions, log_stream, show_nonmatching=False):\n",
    "        self._log_stream_name = log_stream\n",
    "        self._show_nonmatching = show_nonmatching\n",
    "        self.reset_log()\n",
    "        self._next_token = None\n",
    "        self._cwl = boto3.client('logs')\n",
    "        self._log_group = \"/aws/sagemaker/TrainingJobs\"\n",
    "        self._metric_defns = []\n",
    "        for md in metric_definitions:\n",
    "            self.set_metric_definition(md['Name'],md['Regex'])\n",
    "\n",
    "    def set_metric_definition(self, name, regex):\n",
    "        \"\"\"Add or replace a metric definition with the specified name.\n",
    "        \"\"\"\n",
    "        # Remove existing metric with this name if it's already in the list\n",
    "        self._metric_defns = [md for md in self._metric_defns if md['Name'] != name]\n",
    "        # Build the new entry\n",
    "        md = {\n",
    "            'Name': name,\n",
    "            'Regex': regex,\n",
    "        }\n",
    "        try:\n",
    "            md['re'] = re.compile(md['Regex'])\n",
    "        except:\n",
    "            print(\"Failed to compile regex for MetricDefinition %s.\" % md['Name'])\n",
    "            raise\n",
    "        self._metric_defns.append(md)           \n",
    "    \n",
    "    def reset_log(self):\n",
    "        \"\"\"Reset to the beginning of the log stream\"\"\"\n",
    "        self._next_token = None\n",
    "    \n",
    "    def next_page(self, show_nonmatching=None):\n",
    "        \"\"\"Fetches a page of log events and processes them all\"\"\"\n",
    "        if not self._metric_defns:\n",
    "            raise RuntimeError(\"No metric definitions defined.  Use .set_metric_definition()\")\n",
    "        if show_nonmatching is not None:\n",
    "            self._show_nonmatching = show_nonmatching\n",
    "        token_args = {}\n",
    "        if self._next_token:\n",
    "            token_args['nextToken'] = self._next_token\n",
    "        events_result = self._cwl.get_log_events(logGroupName=self._log_group, \n",
    "                                                 logStreamName=self._log_stream_name,\n",
    "                                                 **token_args)\n",
    "        self._next_token = events_result['nextForwardToken']\n",
    "        matches = 0\n",
    "        cnt = 0\n",
    "        for event in events_result['events']:\n",
    "            msg = event['message']\n",
    "            matches += self.process_message(msg)\n",
    "            cnt += 1\n",
    "        print(\"Done with page.  Found matches on %d of %d lines\" % (matches,cnt))\n",
    "            \n",
    "    def process_message(self, msg):\n",
    "        \"\"\"Processes a single cloudwatch event against the defined metrics\"\"\"\n",
    "        html = None\n",
    "        for md in self._metric_defns:\n",
    "            match = md['re'].search(msg)\n",
    "            if match:\n",
    "                if not html:\n",
    "                    # Print the line on the first match\n",
    "                    html = \"<div><div style='background-color:#afa'>line matched: '<tt>%s</tt>'</div>\\n\" % msg\n",
    "                html += \"\"\"\n",
    "                    <ul>\n",
    "                        <b>Metric %s matched</b><br/>\n",
    "                        match='<tt>%s</tt>'<br/>\n",
    "                        captured value='<tt>%s</tt>'\n",
    "                    </ul>\"\"\" % (md['Name'], match.group(0), match.group(1))\n",
    "        if html:\n",
    "            html += \"</div>\\n\"\n",
    "            display(HTML(html))\n",
    "            return 1\n",
    "        else:\n",
    "            if self._show_nonmatching:\n",
    "                display(HTML(\"<div style='background-color:#ccc'>no-match: '<tt>%s</tt>'</div>\" % msg))\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdv = MetricDefinitionVerifier(metric_definitions, log_stream, show_nonmatching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process the first page of log events, but only show lines with matches\n",
    "mdv.next_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can call this method repeatedly to go through the log\n",
    "mdv.next_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try setting a new metric definition and see how it works.\n",
    "mdv.set_metric_definition(name=\"loss\", regex=\"loss = ([0-9\\\\.])+\")\n",
    "mdv.reset_log()\n",
    "mdv.next_page(show_nonmatching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
